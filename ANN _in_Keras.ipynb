{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab0a9abf",
   "metadata": {},
   "source": [
    "# ANN in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e3f12a",
   "metadata": {},
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d751a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "Keras version: 3.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b7a222",
   "metadata": {},
   "source": [
    "Q2. Load the Wine Quality dataset and explore its dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c7a38",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "wine_quality_data = pd.read_csv(\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e150f5",
   "metadata": {},
   "source": [
    "Q3. Check for null values, identify categorical variables, and encode them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e0a48",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "wine_quality_data = pd.read_csv(\"wine_quality.csv\")\n",
    "\n",
    "null_values = wine_quality_data.isnull().sum()\n",
    "print(\"Null values:\\n\", null_values)\n",
    "\n",
    "categorical_cols = wine_quality_data.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical variables:\\n\", categorical_cols)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    wine_quality_data[col] = label_encoder.fit_transform(wine_quality_data[col])\n",
    "\n",
    "print(\"Updated dataset with encoded categorical variables:\\n\", wine_quality_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67146f38",
   "metadata": {},
   "source": [
    "\n",
    "X = wine_quality_data.drop(columns=['target_column_name'])\n",
    "y = wine_quality_data['target_column_name']\n",
    "\n",
    "print(\"Dimensions of features (X):\", X.shape)\n",
    "print(\"Dimensions of target variable (y):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca2850",
   "metadata": {},
   "source": [
    "Q5. Perform a train-test split, dividing the data into training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8e7bf",
   "metadata": {},
   "source": [
    "We perform an initial train-test split to create a temporary dataset for training and testing.\n",
    "Then, we further split the temporary dataset into training and validation datasets using the same function.\n",
    "We print the dimensions of the resulting datasets to verify the split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6f98",
   "metadata": {},
   "source": [
    "Q6. Scale the dataset using an appropriate scaling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b297cce",
   "metadata": {},
   "source": [
    "This code snippet demonstrates how to scale the features using standardization. You fit the scaler to the training data and then transform both the training and validation/test data using the same scaler. This ensures that the same transformation is applied consistently across all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1203b52",
   "metadata": {},
   "source": [
    "Q7. Design and implement at least two hidden layers and an output layer for the binary categorical\n",
    "variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc1ee3",
   "metadata": {},
   "source": [
    "We define the number of input features based on the shape of the scaled training data.\n",
    "We initialize a Sequential model, which represents a linear stack of layers.\n",
    "We add two hidden layers with ReLU activation functions and specify the number of neurons in each layer.\n",
    "For the output layer, we use a single neuron with a sigmoid activation function, suitable for binary classification tasks.\n",
    "We compile the model using binary cross-entropy as the loss function and the Adam optimizer.\n",
    "Finally, we print a summary of the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6350db",
   "metadata": {},
   "source": [
    "Q8. Create a Sequential model in Keras and add the previously designed layers to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28497c",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))  # First hidden layer\n",
    "model.add(Dense(32, activation='relu'))  # Second hidden layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55658edf",
   "metadata": {},
   "source": [
    "Q9. Print the summary of the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf141d",
   "metadata": {},
   "source": [
    "After compiling the model, simply call the summary() method on the model object, and it will print a summary of the model architecture, including the number of parameters in each layer and the total number of parameters in the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4d211",
   "metadata": {},
   "source": [
    "Q10. Set the loss function(‘binary_crossentropy’), optimizer, and include the accuracy metric in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4649a70d",
   "metadata": {},
   "source": [
    "loss='binary_crossentropy' sets the loss function to binary cross-entropy, which is commonly used for binary classification tasks.\n",
    "optimizer='adam' sets the optimizer to Adam, which is an efficient optimization algorithm.\n",
    "metrics=['accuracy'] includes accuracy as a metric to monitor during training. This will print the accuracy of the model on the training and validation sets during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a20b0",
   "metadata": {},
   "source": [
    "Q11. Compile the model with the specified loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47dbcc4",
   "metadata": {},
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d500c6",
   "metadata": {},
   "source": [
    "Q12. Fit the model to the training data using appropriate batch size and number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830cbc0",
   "metadata": {},
   "source": [
    "After fitting the model, the history object contains information about the training process, including training and validation loss and accuracy for each epoch. You can use this information to visualize the training progress and diagnose any issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf65d5",
   "metadata": {},
   "source": [
    "Q13. Obtain the model's parameters (weights and biases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba4cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "We iterate through each layer in the model.\n",
    "For each layer, we use the get_weights() method to obtain the weights and biases.\n",
    "We store the weights and biases for each layer in a list.\n",
    "Finally, we print the weights and biases for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c83caa",
   "metadata": {},
   "source": [
    "Q14. Store the model's training history as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35878121",
   "metadata": {},
   "source": [
    "We iterate through each layer in the model.\n",
    "For each layer, we use the get_weights() method to obtain the weights and biases.\n",
    "We store the weights and biases for each layer in a list.\n",
    "Finally, we print the weights and biases for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f91451",
   "metadata": {},
   "source": [
    "Q15. Plot the training history (e.g., accuracy and loss) using suitable visualization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153f2cc",
   "metadata": {},
   "source": [
    "We use plt.plot() to plot the training and validation accuracy values over epochs.\n",
    "We use plt.title(), plt.xlabel(), and plt.ylabel() to set the title and labels for the plot.\n",
    "We use plt.legend() to add a legend indicating the training and validation curves.\n",
    "We repeat the same process for plotting the training and validation loss values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a547b",
   "metadata": {},
   "source": [
    "Q16. Evaluate the model's performance using the test dataset and report relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
