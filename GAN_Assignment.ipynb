{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2be0651",
   "metadata": {},
   "source": [
    "# GAN Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaae22f",
   "metadata": {},
   "source": [
    "Question 1: Use any GAN of your choice (preferably DCGAN) to generate images from noise. Perform the\n",
    "following experiments.\n",
    "A. Use the CIFAR 10 database to learn the GAN network. Generate images once the learning is complete.\n",
    "B. Plot generator and discriminator losses and show how can you ascertain the convergence of the GAN\n",
    "training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccf198",
   "metadata": {},
   "source": [
    "A. To generate images using a DCGAN trained on CIFAR-10:\n",
    "\n",
    "Train the DCGAN on the CIFAR-10 dataset.\n",
    "After training, feed random noise into the generator to produce new images.\n",
    "B. To ascertain the convergence of the GAN training process:\n",
    "\n",
    "Plot the generator and discriminator losses over epochs.\n",
    "Look for stabilization or convergence of the losses as training progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfc391",
   "metadata": {},
   "source": [
    "2: Fine-tuning Take a ResNet50 model and the database to be used for this question is CIFAR-10.\n",
    "Remove its classification layer and place a 2-layer neural network followed by a Softmax layer. Calculate\n",
    "classification accuracy on a train set, test set, and plot accuracies over epochs when:\n",
    "\n",
    "A. The complete network is trained from scratch (i.e, random weights)\n",
    "B. A pre-trained ResNet50 on ImageNet weights is used and only the neural network layers are trained\n",
    "(i.e, weights of layers of ResNet50 are kept frozen and unchanged)\n",
    "C. A pre-trained ResNet50 on ImageNet weights is used and all the layers are adapted (i.e, weights of\n",
    "layers of ResNet50 are also updated now)\n",
    "D. Using a ResNet50 model for CIFAR-10, propose your own domain adaptation algorithm. To get full\n",
    "credit for this part, the accuracy on the test set should be more than what was reported in part 3. You\n",
    "may build upon part(3) to propose your own algorithm. Explain why your proposed algorithm is\n",
    "working better. You may use any training data as long as it involves using other datasets (on which\n",
    "youâ€™ll adapt CIFAR-10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85782e04",
   "metadata": {},
   "source": [
    "A. Training from Scratch:\n",
    "\n",
    "Remove the classification layer from ResNet50.\n",
    "Add a 2-layer neural network and a Softmax layer.\n",
    "Plot accuracies over epochs.\n",
    "\n",
    "Load pre-trained ResNet50 weights trained on ImageNet.\n",
    "Remove the classification layer.\n",
    "C. Transfer Learning with Adapted ResNet50 Weights:\n",
    "\n",
    "Load pre-trained ResNet50 weights trained on ImageNet.\n",
    "Remove the classification layer.\n",
    "Add a 2-layer neural network and a Softmax layer.\n",
    "D. Domain Adaptation Algorithm:\n",
    "\n",
    "Propose a domain adaptation algorithm using ResNet50 for CIFAR-10.\n",
    "Use other datasets for adaptation.\n",
    "Train the adapted model on CIFAR-10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17eabb",
   "metadata": {},
   "source": [
    "1. Data Augmentation Function for GAN Training\n",
    "Write a Python function that generates augmented data for training a GAN. The function should take\n",
    "an image dataset as input and apply data augmentation techniques commonly used in GAN training,\n",
    "such as random rotation, flipping, and cropping. The function should return the augmented dataset.\n",
    "You can use popular image-processing libraries like OpenCV or PIL to perform these augmentations.\n",
    "Ensure that the function allows customization of augmentation parameters, such as rotation angles,\n",
    "flip probability, and crop size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e503f",
   "metadata": {},
   "source": [
    "# Coading Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9dbae7",
   "metadata": {},
   "source": [
    "1. Data Augmentation Function for GAN Training\n",
    "Write a Python function that generates augmented data for training a GAN. The function should take\n",
    "an image dataset as input and apply data augmentation techniques commonly used in GAN training,\n",
    "such as random rotation, flipping, and cropping. The function should return the augmented dataset.\n",
    "You can use popular image-processing libraries like OpenCV or PIL to perform these augmentations.\n",
    "Ensure that the function allows customization of augmentation parameters, such as rotation angles,\n",
    "flip probability, and crop size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafa5a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_augmentation\u001b[39m(images, rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, flip_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, crop_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)):\n\u001b[0;32m      8\u001b[0m     augmented_images \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "def data_augmentation(images, rotation_range=30, flip_prob=0.5, crop_size=(64, 64)):\n",
    "   \n",
    "    augmented_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Convert image to numpy array\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        # Random rotation\n",
    "        angle = random.uniform(-rotation_range, rotation_range)\n",
    "        image_array = Image.fromarray(image_array)\n",
    "        image_array = image_array.rotate(angle, resample=Image.BICUBIC)\n",
    "\n",
    "        # Horizontal flipping\n",
    "        if random.random() < flip_prob:\n",
    "            image_array = image_array.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        # Random cropping\n",
    "        width, height = image_array.size\n",
    "        left = random.randint(0, width - crop_size[1])\n",
    "        top = random.randint(0, height - crop_size[0])\n",
    "        right = left + crop_size[1]\n",
    "        bottom = top + crop_size[0]\n",
    "        image_array = image_array.crop((left, top, right, bottom))\n",
    "\n",
    "        augmented_images.append(image_array)\n",
    "\n",
    "    return augmented_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3547aef",
   "metadata": {},
   "source": [
    "2.Create a simple discriminator model using tensorflow keras which can classify a image as real or\n",
    "fake. You can use random noise same size as the image to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097ec79",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def discriminator_model(input_shape):\n",
    "\n",
    "    input_image = layers.Input(shape=input_shape)\n",
    "\n",
    "    flat_image = layers.Flatten()(input_image)\n",
    "\n",
    "    x = layers.Dense(128, activation='relu')(flat_image)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    discriminator = models.Model(input_image, output, name='discriminator')\n",
    "\n",
    "    return discriminator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417dd78",
   "metadata": {},
   "source": [
    "3.Create a generator model with uses transpose convolution to generate 32 x 32 x 3 images from\n",
    "random noise. In this question you can just define the model architecture for the generator and make\n",
    "sure that the model is generating the desired image size , you can take a latent space dimension as a\n",
    "array of 100 float values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429781f3",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def generator_model(latent_dim):\n",
    "    # Input layer for the latent space vector\n",
    "    input_latent = layers.Input(shape=(latent_dim,))\n",
    "\n",
    "    # Dense layer to map the latent space to a suitable shape for convolutional layers\n",
    "    x = layers.Dense(4 * 4 * 256, activation='relu')(input_latent)\n",
    "    x = layers.Reshape((4, 4, 256))(x)\n",
    "\n",
    "    # Transpose convolutional layers to upsample the input\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "\n",
    "    # Output layer with sigmoid activation to generate 32 x 32 x 3 images\n",
    "    output_image = layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='sigmoid')(x)\n",
    "\n",
    "    # Create the generator model\n",
    "    generator = models.Model(input_latent, output_image, name='generator')\n",
    "\n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633b3d0",
   "metadata": {},
   "source": [
    "4. Implementing a Minimax Loss Function for GANs\n",
    "Write a Python function that calculates the Minimax loss for a GAN. The function should take as input\n",
    "the predictions (scores) from a discriminator and return the Minimax loss.\n",
    "The Minimax loss function for GANs is typically defined as follows:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7691af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimax_loss\u001b[39m(real_scores, generated_scores):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Calculate the loss for real and generated images\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     real_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msigmoid_cross_entropy_with_logits(labels\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mones_like(real_scores), logits\u001b[38;5;241m=\u001b[39mreal_scores))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def minimax_loss(real_scores, generated_scores):\n",
    "    # Calculate the loss for real and generated images\n",
    "    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(real_scores), logits=real_scores))\n",
    "    generated_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(generated_scores), logits=generated_scores))\n",
    "    \n",
    "    # Total Minimax loss\n",
    "    minimax_loss = real_loss + generated_loss\n",
    "    \n",
    "    return minimax_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3095900",
   "metadata": {},
   "source": [
    "5.Use the models made in question 2,3 and make your own GAN model by connecting the generator and\n",
    "the discriminator to generate images from random noise , You can use CIFAR -10 dataset. Find some\n",
    "tips on creating your own GAN here :https://machinelearningmastery.com/how-to-code-generative-\n",
    "adversarial-network-hacks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136c92d",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "\n",
    "def create_gan(generator, discriminator):\n",
    "    # Make the discriminator layers non-trainable\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Create a sequential model\n",
    "    gan = models.Sequential()\n",
    "\n",
    "    # Add the generator followed by the discriminator\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "\n",
    "    return gan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76698c5c",
   "metadata": {},
   "source": [
    "6. Transfer Learning with GANs on the CIFAR-10 Dataset\n",
    "Transfer learning is commonly used to improve GAN performance. In this question, you should\n",
    "implement a GAN for image generation using transfer learning. The data source is the CIFAR-10\n",
    "dataset, which is a dataset of 60,000 32x32 color images in 10 different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92366c20",
   "metadata": {},
   "source": [
    "Load the CIFAR-10 Dataset:\n",
    "Choose Pre-trained Models:\n",
    "Modify the Generator and Discriminator: \n",
    "Freeze Pre-trained Layers (Optional): \n",
    "Training Procedure: \n",
    "Evaluate the Results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c583988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
