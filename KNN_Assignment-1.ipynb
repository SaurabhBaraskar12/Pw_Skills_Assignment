{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447cf312",
   "metadata": {},
   "source": [
    "# KNN Assignment-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e143e",
   "metadata": {},
   "source": [
    "Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bded85",
   "metadata": {},
   "source": [
    "\n",
    "The K-Nearest Neighbors (KNN) algorithm is a simple supervised machine learning algorithm used for classification and regression tasks. It makes predictions based on the similarity between new data points and existing data points in the training dataset, by selecting the K nearest neighbors. For classification, it assigns the most common class label among the neighbors, and for regression, it computes the average of the target values.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d49410e",
   "metadata": {},
   "source": [
    "Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c465da",
   "metadata": {},
   "source": [
    "the choice of K depends on the specific dataset and problem at hand, and it often involves experimentation and validation to determine the optimal value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc2306",
   "metadata": {},
   "source": [
    "Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d1dc2",
   "metadata": {},
   "source": [
    "In summary, while both KNN classifier and KNN regressor use the same underlying principle of finding the K nearest neighbors to make predictions, they differ in the type of prediction they make (classification vs. regression) and the nature of the target variable (categorical vs. continuous)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31bd49",
   "metadata": {},
   "source": [
    "Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537616d0",
   "metadata": {},
   "source": [
    "When evaluating the performance of KNN, it's important to consider the specific characteristics of the dataset and the goals of the analysis to choose the most appropriate evaluation metrics. Additionally, cross-validation techniques such as k-fold cross-validation can be used to obtain more robust estimates of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403115e",
   "metadata": {},
   "source": [
    "Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e27c9",
   "metadata": {},
   "source": [
    "To mitigate the curse of dimensionality in KNN and other algorithms, dimensionality reduction techniques such as feature selection, feature extraction, or manifold learning can be applied to reduce the number of dimensions while preserving relevant information. Additionally, careful feature engineering and regularization techniques can help alleviate the effects of high dimensionality on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27146f94",
   "metadata": {},
   "source": [
    "Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98eff02",
   "metadata": {},
   "source": [
    "It's essential to carefully evaluate the chosen approach based on the specific characteristics of the dataset, the extent of missingness, and the impact on the performance of the KNN algorithm. Additionally, preprocessing steps such as imputation should be performed separately on the training and test datasets to avoid data leakage and ensure unbiased evaluation of model performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2838849",
   "metadata": {},
   "source": [
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff03b0b3",
   "metadata": {},
   "source": [
    "In summary, the choice between KNN classifier and regressor depends on the problem at hand and the nature of the target variable. If the target variable is categorical, and the goal is to classify instances into discrete classes, then KNN classifier is more appropriate. On the other hand, if the target variable is continuous, and the goal is to predict numerical values, then KNN regressor is more suitable. It's important to experiment with both approaches and evaluate their performance using appropriate metrics to determine which one works better for a specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c107ac",
   "metadata": {},
   "source": [
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
    "and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf611997",
   "metadata": {},
   "source": [
    "By addressing these weaknesses and leveraging its strengths, KNN can be effectively used for both classification and regression tasks in various domains. However, it's essential to carefully consider the characteristics of the dataset and the specific requirements of the problem to determine if KNN is the most suitable algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d303b4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `KNN` not found.\n"
     ]
    }
   ],
   "source": [
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfe7be",
   "metadata": {},
   "source": [
    " the main difference between Euclidean distance and Manhattan distance lies in how they measure distance between points. Euclidean distance considers the straight-line distance between points, while Manhattan distance considers the sum of the absolute differences along each dimension. The choice between the two distance metrics depends on the characteristics of the dataset and the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53d43f",
   "metadata": {},
   "source": [
    "Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae49851",
   "metadata": {},
   "source": [
    "feature scaling ensures that the KNN algorithm performs effectively and accurately by mitigating the impact of feature scales on distance calculations and neighbor selection. It's an essential preprocessing step that helps improve the performance and stability of the KNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6c8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
